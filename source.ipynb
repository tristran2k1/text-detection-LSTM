{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914309d6",
   "metadata": {},
   "source": [
    "#### Reference: https://github.com/bnsreenu/python_for_microscopists/blob/master/167-LSTM_text_generation_ENGLISH.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b9ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830326b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿the project gutenberg ebook of the jungle book, by rudyard kipling\n",
      "\n",
      "this ebook is for the use of an\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "filename = \"./jungle_book.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "print(raw_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec6b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN TEXT : remove number\n",
    "raw_text = ''.join(c for c in raw_text if not c.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a1849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text))) #List of every character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c0de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of characters mapped to integer values\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "#Do the reverse so we can print our predictions in characters and not integers\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1257ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in the text; corpus length:  292870\n",
      "Total Vocab:  51\n"
     ]
    }
   ],
   "source": [
    "# summarize the data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters in the text; corpus length: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f90abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 29281\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60  #Length of each input sequence\n",
    "step = 10 \n",
    "sentences = []    # X values (Sentences)\n",
    "next_chars = []   # Y values: next value follow X\n",
    "for i in range(0, n_chars - seq_length, step):  #step=1 means each sentence is offset just by a single letter\n",
    "    sentences.append(raw_text[i: i + seq_length])  #Sequence in\n",
    "    next_chars.append(raw_text[i + seq_length])  #Sequence out\n",
    "n_patterns = len(sentences)    \n",
    "print('Number of sequences:', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1e57a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29281, 60, 51)\n",
      "(29281, 51)\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False  True False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False  True False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False  True False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]]\n"
     ]
    }
   ],
   "source": [
    "#Vectorization returns a vector for all sentences indicating the presence or absence of a character. \n",
    "\n",
    "x = np.zeros((len(sentences), seq_length, n_vocab), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), n_vocab), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1\n",
    "    \n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c916f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               92160     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 51)                6579      \n",
      "=================================================================\n",
      "Total params: 98,739\n",
      "Trainable params: 98,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, n_vocab)))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247db3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68eaf905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.6643\n",
      "Epoch 00001: loss improved from inf to 0.66430, saving model to saved_weights\\saved_weights-01-0.6643.hdf5\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.6643\n",
      "Epoch 2/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.6188\n",
      "Epoch 00002: loss improved from 0.66430 to 0.61878, saving model to saved_weights\\saved_weights-02-0.6188.hdf5\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 0.6188\n",
      "Epoch 3/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.6177\n",
      "Epoch 00003: loss improved from 0.61878 to 0.61774, saving model to saved_weights\\saved_weights-03-0.6177.hdf5\n",
      "229/229 [==============================] - 19s 83ms/step - loss: 0.6177\n",
      "Epoch 4/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.6140\n",
      "Epoch 00004: loss improved from 0.61774 to 0.61354, saving model to saved_weights\\saved_weights-04-0.6135.hdf5\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.6135\n",
      "Epoch 5/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5968\n",
      "Epoch 00005: loss improved from 0.61354 to 0.59681, saving model to saved_weights\\saved_weights-05-0.5968.hdf5\n",
      "229/229 [==============================] - 15s 64ms/step - loss: 0.5968\n",
      "Epoch 6/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5993\n",
      "Epoch 00006: loss did not improve from 0.59681\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.5990\n",
      "Epoch 7/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5928\n",
      "Epoch 00007: loss improved from 0.59681 to 0.59285, saving model to saved_weights\\saved_weights-07-0.5928.hdf5\n",
      "229/229 [==============================] - 15s 66ms/step - loss: 0.5928\n",
      "Epoch 8/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5771\n",
      "Epoch 00008: loss improved from 0.59285 to 0.57707, saving model to saved_weights\\saved_weights-08-0.5771.hdf5\n",
      "229/229 [==============================] - 15s 66ms/step - loss: 0.5771\n",
      "Epoch 9/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5798\n",
      "Epoch 00009: loss did not improve from 0.57707\n",
      "229/229 [==============================] - 14s 59ms/step - loss: 0.5798\n",
      "Epoch 10/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5696\n",
      "Epoch 00010: loss improved from 0.57707 to 0.56941, saving model to saved_weights\\saved_weights-10-0.5694.hdf5\n",
      "229/229 [==============================] - 14s 62ms/step - loss: 0.5694\n",
      "Epoch 11/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5601\n",
      "Epoch 00011: loss improved from 0.56941 to 0.55989, saving model to saved_weights\\saved_weights-11-0.5599.hdf5\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.5599\n",
      "Epoch 12/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5426\n",
      "Epoch 00012: loss improved from 0.55989 to 0.54306, saving model to saved_weights\\saved_weights-12-0.5431.hdf5\n",
      "229/229 [==============================] - 14s 61ms/step - loss: 0.5431\n",
      "Epoch 13/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5480\n",
      "Epoch 00013: loss did not improve from 0.54306\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.5480\n",
      "Epoch 14/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5361\n",
      "Epoch 00014: loss improved from 0.54306 to 0.53606, saving model to saved_weights\\saved_weights-14-0.5361.hdf5\n",
      "229/229 [==============================] - 15s 66ms/step - loss: 0.5361\n",
      "Epoch 15/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5398\n",
      "Epoch 00015: loss did not improve from 0.53606\n",
      "229/229 [==============================] - 15s 67ms/step - loss: 0.5398\n",
      "Epoch 16/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5332\n",
      "Epoch 00016: loss improved from 0.53606 to 0.53325, saving model to saved_weights\\saved_weights-16-0.5332.hdf5\n",
      "229/229 [==============================] - 18s 78ms/step - loss: 0.5332\n",
      "Epoch 17/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5237\n",
      "Epoch 00017: loss improved from 0.53325 to 0.52436, saving model to saved_weights\\saved_weights-17-0.5244.hdf5\n",
      "229/229 [==============================] - 18s 79ms/step - loss: 0.5244\n",
      "Epoch 18/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5139\n",
      "Epoch 00018: loss improved from 0.52436 to 0.51391, saving model to saved_weights\\saved_weights-18-0.5139.hdf5\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 0.5139\n",
      "Epoch 19/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.5069\n",
      "Epoch 00019: loss improved from 0.51391 to 0.50746, saving model to saved_weights\\saved_weights-19-0.5075.hdf5\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 0.5075\n",
      "Epoch 20/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.5065\n",
      "Epoch 00020: loss improved from 0.50746 to 0.50654, saving model to saved_weights\\saved_weights-20-0.5065.hdf5\n",
      "229/229 [==============================] - 26s 113ms/step - loss: 0.5065\n",
      "Epoch 21/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4981\n",
      "Epoch 00021: loss improved from 0.50654 to 0.49806, saving model to saved_weights\\saved_weights-21-0.4981.hdf5\n",
      "229/229 [==============================] - 24s 104ms/step - loss: 0.4981\n",
      "Epoch 22/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4946\n",
      "Epoch 00022: loss improved from 0.49806 to 0.49461, saving model to saved_weights\\saved_weights-22-0.4946.hdf5\n",
      "229/229 [==============================] - 28s 121ms/step - loss: 0.4946\n",
      "Epoch 23/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4916\n",
      "Epoch 00023: loss improved from 0.49461 to 0.49161, saving model to saved_weights\\saved_weights-23-0.4916.hdf5\n",
      "229/229 [==============================] - 25s 108ms/step - loss: 0.4916\n",
      "Epoch 24/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4866\n",
      "Epoch 00024: loss improved from 0.49161 to 0.48662, saving model to saved_weights\\saved_weights-24-0.4866.hdf5\n",
      "229/229 [==============================] - 25s 110ms/step - loss: 0.4866\n",
      "Epoch 25/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4843\n",
      "Epoch 00025: loss improved from 0.48662 to 0.48408, saving model to saved_weights\\saved_weights-25-0.4841.hdf5\n",
      "229/229 [==============================] - 28s 124ms/step - loss: 0.4841\n",
      "Epoch 26/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4865\n",
      "Epoch 00026: loss did not improve from 0.48408\n",
      "229/229 [==============================] - 14s 61ms/step - loss: 0.4863\n",
      "Epoch 27/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4773\n",
      "Epoch 00027: loss improved from 0.48408 to 0.47752, saving model to saved_weights\\saved_weights-27-0.4775.hdf5\n",
      "229/229 [==============================] - 13s 58ms/step - loss: 0.4775\n",
      "Epoch 28/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4743\n",
      "Epoch 00028: loss improved from 0.47752 to 0.47425, saving model to saved_weights\\saved_weights-28-0.4743.hdf5\n",
      "229/229 [==============================] - 14s 63ms/step - loss: 0.4743\n",
      "Epoch 29/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4690\n",
      "Epoch 00029: loss improved from 0.47425 to 0.46903, saving model to saved_weights\\saved_weights-29-0.4690.hdf5\n",
      "229/229 [==============================] - 16s 71ms/step - loss: 0.4690\n",
      "Epoch 30/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4658\n",
      "Epoch 00030: loss improved from 0.46903 to 0.46632, saving model to saved_weights\\saved_weights-30-0.4663.hdf5\n",
      "229/229 [==============================] - 17s 73ms/step - loss: 0.4663\n",
      "Epoch 31/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4552\n",
      "Epoch 00031: loss improved from 0.46632 to 0.45524, saving model to saved_weights\\saved_weights-31-0.4552.hdf5\n",
      "229/229 [==============================] - 13s 59ms/step - loss: 0.4552\n",
      "Epoch 32/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.4440\n",
      "Epoch 00032: loss improved from 0.45524 to 0.44426, saving model to saved_weights\\saved_weights-32-0.4443.hdf5\n",
      "229/229 [==============================] - 14s 63ms/step - loss: 0.4443\n",
      "Epoch 33/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4403\n",
      "Epoch 00033: loss improved from 0.44426 to 0.44028, saving model to saved_weights\\saved_weights-33-0.4403.hdf5\n",
      "229/229 [==============================] - 15s 65ms/step - loss: 0.4403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4416\n",
      "Epoch 00034: loss did not improve from 0.44028\n",
      "229/229 [==============================] - 14s 63ms/step - loss: 0.4416\n",
      "Epoch 35/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4409\n",
      "Epoch 00035: loss did not improve from 0.44028\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.4409\n",
      "Epoch 36/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4337\n",
      "Epoch 00036: loss improved from 0.44028 to 0.43373, saving model to saved_weights\\saved_weights-36-0.4337.hdf5\n",
      "229/229 [==============================] - 19s 82ms/step - loss: 0.4337\n",
      "Epoch 37/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4278\n",
      "Epoch 00037: loss improved from 0.43373 to 0.42777, saving model to saved_weights\\saved_weights-37-0.4278.hdf5\n",
      "229/229 [==============================] - 18s 77ms/step - loss: 0.4278\n",
      "Epoch 38/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4210\n",
      "Epoch 00038: loss improved from 0.42777 to 0.42103, saving model to saved_weights\\saved_weights-38-0.4210.hdf5\n",
      "229/229 [==============================] - 17s 75ms/step - loss: 0.4210\n",
      "Epoch 39/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4233\n",
      "Epoch 00039: loss did not improve from 0.42103\n",
      "229/229 [==============================] - 16s 72ms/step - loss: 0.4233\n",
      "Epoch 40/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4205\n",
      "Epoch 00040: loss improved from 0.42103 to 0.42053, saving model to saved_weights\\saved_weights-40-0.4205.hdf5\n",
      "229/229 [==============================] - 22s 95ms/step - loss: 0.4205\n",
      "Epoch 41/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4153\n",
      "Epoch 00041: loss improved from 0.42053 to 0.41530, saving model to saved_weights\\saved_weights-41-0.4153.hdf5\n",
      "229/229 [==============================] - 39s 171ms/step - loss: 0.4153\n",
      "Epoch 42/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4109\n",
      "Epoch 00042: loss improved from 0.41530 to 0.41094, saving model to saved_weights\\saved_weights-42-0.4109.hdf5\n",
      "229/229 [==============================] - 29s 125ms/step - loss: 0.4109\n",
      "Epoch 43/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4031\n",
      "Epoch 00043: loss improved from 0.41094 to 0.40311, saving model to saved_weights\\saved_weights-43-0.4031.hdf5\n",
      "229/229 [==============================] - 33s 142ms/step - loss: 0.4031\n",
      "Epoch 44/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.4051\n",
      "Epoch 00044: loss did not improve from 0.40311\n",
      "229/229 [==============================] - 35s 152ms/step - loss: 0.4051\n",
      "Epoch 45/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3966\n",
      "Epoch 00045: loss improved from 0.40311 to 0.39658, saving model to saved_weights\\saved_weights-45-0.3966.hdf5\n",
      "229/229 [==============================] - 33s 146ms/step - loss: 0.3966\n",
      "Epoch 46/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3946\n",
      "Epoch 00046: loss improved from 0.39658 to 0.39456, saving model to saved_weights\\saved_weights-46-0.3946.hdf5\n",
      "229/229 [==============================] - 33s 146ms/step - loss: 0.3946\n",
      "Epoch 47/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3854\n",
      "Epoch 00047: loss improved from 0.39456 to 0.38545, saving model to saved_weights\\saved_weights-47-0.3854.hdf5\n",
      "229/229 [==============================] - 29s 125ms/step - loss: 0.3854\n",
      "Epoch 48/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3973\n",
      "Epoch 00048: loss did not improve from 0.38545\n",
      "229/229 [==============================] - 34s 149ms/step - loss: 0.3973\n",
      "Epoch 49/50\n",
      "228/229 [============================>.] - ETA: 0s - loss: 0.3894\n",
      "Epoch 00049: loss did not improve from 0.38545\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 0.3894\n",
      "Epoch 50/50\n",
      "229/229 [==============================] - ETA: 0s - loss: 0.3897\n",
      "Epoch 00050: loss did not improve from 0.38545\n",
      "229/229 [==============================] - 18s 80ms/step - loss: 0.3897\n"
     ]
    }
   ],
   "source": [
    "filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "history = model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=50,   \n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "model.save('weights_jungle_book_50epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748acd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea7b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate character\n",
    "def GenerateCharacter(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b947058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Seed for our text prediction: \"scribing it.\n",
      "\n",
      "“the red flower?” said mowgli. “that grows out\"\n",
      " of the holdaling fit bord\n",
      "wolf elephants \n",
      "to any one could bere,” said bit the moon wolf, whand his hee liever alwass\n",
      "he caug, hai is but the jungle whent deart and are\n",
      "and agred him in\n",
      "fromesick. he had to kill..\n",
      "“what’t i he is i kee.”\n",
      "\n",
      "“b’sth rikki-tikki knew the clakes, on the pack and livelb, then i little brown soffring\n",
      "with your to ever withor ne pooked and mowgli begioce, and mowgli at th\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights_jungle_book_50epochs.h5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "#Pick a random sentence from the text as seed.\n",
    "start_index = random.randint(0, n_chars - seq_length - 1)\n",
    "\n",
    "#Initiate generated text and keep adding new predictions and print them out\n",
    "generated = ''\n",
    "sentence = raw_text[start_index: start_index + seq_length]\n",
    "generated += sentence\n",
    "\n",
    "print('----- Seed for our text prediction: \"' + sentence + '\"')\n",
    "\n",
    "\n",
    "for i in range(400):   # Number of characters including spaces\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = GenerateCharacter(preds)\n",
    "    next_char = int_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e91acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
